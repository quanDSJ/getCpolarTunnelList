import requests
import webbrowser
import json
import os
import time
import logging
from collections import defaultdict
from bs4 import BeautifulSoup
from threading import Timer

art = """
   ___                             ____                                      
  / _ \   _   _    __ _   _ __    / ___|    ___   _ __  __   __   ___   _ __ 
 | | | | | | | |  / _` | | '_ \   \___ \   / _ \ | '__| \ \ / /  / _ \ | '__|
 | |_| | | |_| | | (_| | | | | |   ___) | |  __/ | |     \ V /  |  __/ | |   
  \__\_\  \__,_|  \__,_| |_| |_|  |____/   \___| |_|      \_/    \___| |_|   
                                                    """

print(art)
art1 = """
                                        ___-------___
                                   _-~~             ~~-_
                                _-~                    /~-_
             /^\\__/^\\         /~  \\                   /    \\
           /|  O|| O|        /      \\_______________/        \\
          | |___||__|      /       /                \\          \\
          |          \\    /      /                    \\          \\
          |   (_______) /______/                        \\_________ \\
          |         / /         \\                      /            \\
           \\         \\^\\         \\                  /               \\     /
             \\         ||           \\______________/      _-_       //\\__//
               \\       ||------_-~~-_ ------------- \\ --/~   ~\\    || __/
                 ~-----||====/~     |==================|       |/~~~~~
                  (_(__/  ./     /                    \\_      \\.
                         (_(___/                         \\_____)_)-qj.25.10.4
                         """
print(art1)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡ï¼šç”¨äºè¶…æ—¶è‡ªåŠ¨æ‰“å¼€
g_selected_url = None
g_timer = None


def load_config():
    """ä»JSONæ–‡ä»¶åŠ è½½é…ç½®ï¼ˆåŒ…å«è‡ªåŠ¨æ‰“å¼€çš„éš§é“åç§°ï¼‰"""
    config_path = os.path.join("config", "loginCpolar.json")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
        required_keys = ["CPOLAR_EMAIL", "CPOLAR_PASSWORD", "LOGIN_URL", "AFTER_LOGIN_URL", "TARGET_URL", "AUTO_OPEN_TUNNEL"]
        for key in required_keys:
            if key not in config:
                raise ValueError(f"é…ç½®æ–‡ä»¶ç¼ºå°‘å¿…è¦é¡¹ï¼š{key}")
        logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸï¼Œè‡ªåŠ¨æ‰“å¼€çš„éš§é“åç§°ï¼š{config['AUTO_OPEN_TUNNEL']}")
        return config
    except FileNotFoundError:
        raise Exception(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{config_path}")
    except json.JSONDecodeError:
        raise Exception(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSON")


def login(config):
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/140.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "zh-CN,zh;q=0.9",
        "Accept-Encoding": "gzip, deflate, br, zstd",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    })

    try:
        # 1. è®¿é—®ç™»å½•é¡µé¢
        logger.info("è®¿é—®ç™»å½•é¡µé¢...")
        login_page_resp = session.get(config["LOGIN_URL"], allow_redirects=True, timeout=10)
        login_page_resp.raise_for_status()
        logger.info(f"ç™»å½•é¡µé¢çŠ¶æ€ç : {login_page_resp.status_code}")

        # 2. è§£æè¡¨å•
        logger.info("è§£æç™»å½•è¡¨å•...")
        soup = BeautifulSoup(login_page_resp.text, "html.parser")
        login_form = soup.find("form", id="captcha-form")
        if not login_form:
            raise Exception("æœªæ‰¾åˆ°ç™»å½•è¡¨å•ï¼Œé¡µé¢ç»“æ„å¯èƒ½å˜åŒ–")

        # æå–è¡¨å•å­—æ®µ
        form_data = {}
        for input_tag in login_form.find_all("input"):
            name = input_tag.get("name")
            value = input_tag.get("value", "")
            if name:
                form_data[name] = value
                logger.info(f"æå–è¡¨å•å­—æ®µ: {name} = {value if name != 'password' else '***'}")

        # 3. å¡«å†™è´¦å·å¯†ç 
        form_data["login"] = config["CPOLAR_EMAIL"]
        form_data["password"] = config["CPOLAR_PASSWORD"]

        # 4. å‘é€ç™»å½•è¯·æ±‚
        time.sleep(1)
        logger.info("å‘é€ç™»å½•è¯·æ±‚...")
        login_resp = session.post(
            config["LOGIN_URL"],
            data=form_data,
            headers={
                "Referer": config["LOGIN_URL"],
                "Origin": "https://dashboard.cpolar.com",
                "Content-Type": "application/x-www-form-urlencoded"
            },
            allow_redirects=True,
            timeout=10
        )
        login_resp.raise_for_status()
        logger.info(f"ç™»å½•è¯·æ±‚çŠ¶æ€ç : {login_resp.status_code}")
        logger.info(f"ç™»å½•åè·³è½¬URL: {login_resp.url}")

        # éªŒè¯ç™»å½•æˆåŠŸ
        if login_resp.url != config["AFTER_LOGIN_URL"]:
            raise Exception(f"ç™»å½•æœªè·³è½¬è‡³ç›®æ ‡é¡µï¼Œå½“å‰URL: {login_resp.url}")
        
        logger.info("éªŒè¯/get-startedé¡µé¢å†…å®¹...")
        after_login_resp = session.get(config["AFTER_LOGIN_URL"], timeout=10)
        after_login_resp.raise_for_status()

        if "captcha-form" in after_login_resp.text or "é‚®ç®±" in after_login_resp.text:
            raise Exception("ç™»å½•å¤±è´¥ï¼Œ/get-startedé¡µé¢ä»æ˜¾ç¤ºç™»å½•è¡¨å•")
        
        logger.info("âœ… ç™»å½•æˆåŠŸï¼å·²è¿›å…¥/get-startedé¡µé¢")
        
        # 5. è®¿é—®ç›®æ ‡é¡µ
        logger.info(f"è®¿é—®ç›®æ ‡é¡µ: {config['TARGET_URL']}")
        target_resp = session.get(config["TARGET_URL"], timeout=10)
        target_resp.raise_for_status()
        logger.info(f"ç›®æ ‡é¡µçŠ¶æ€ç : {target_resp.status_code}")

        return target_resp.text

    except requests.exceptions.RequestException as e:
        logger.error(f"ç½‘ç»œé”™è¯¯: {str(e)}", exc_info=True)
    except Exception as e:
        logger.error(f"æ‰§è¡Œé”™è¯¯: {str(e)}", exc_info=True)
    finally:
        session.close()


def parse_cpolar_tunnels(html_content):
    """è§£ææ‰€æœ‰éš§é“ä¿¡æ¯"""
    soup = BeautifulSoup(html_content, 'html.parser')
    tunnel_table = soup.find('table', class_='table table-sm')
    if not tunnel_table:
        raise ValueError("æœªæ‰¾åˆ°éš§é“ä¿¡æ¯è¡¨æ ¼")

    # æå–è¡¨å¤´
    th_tags = tunnel_table.find('thead').find_all('th')
    columns = [th.get_text(strip=True) for th in th_tags]
    logger.info(f"è§£æåˆ°è¡¨å¤´ï¼š{columns}")

    # æå–æ•°æ®è¡Œ
    tunnel_data = []
    for tr in tunnel_table.find('tbody').find_all('tr'):
        td_tags = tr.find_all(['td', 'th'])
        row = []
        for tag in td_tags:
            a_tag = tag.find('a')
            row.append(a_tag['href'] if (a_tag and 'href' in a_tag.attrs) else tag.get_text(strip=True))
        
        if len(row) == len(columns):
            tunnel_data.append(dict(zip(columns, row)))
        else:
            logger.warning(f"è·³è¿‡æ ¼å¼å¼‚å¸¸çš„è¡Œï¼š{row}")

    return columns, tunnel_data


def filter_http_https_tunnels(tunnel_data):
    """è¿‡æ»¤å‡ºHTTP/HTTPSéš§é“ï¼Œç›¸åŒåç§°ä¿ç•™HTTPS"""
    filtered = {}
    for tunnel in tunnel_data:
        name = tunnel["éš§é“åç§°"]
        url = tunnel["URL"]
        proto = url.split(":")[0].lower()

        if proto not in ["http", "https"]:
            continue  # è¿‡æ»¤éHTTP/HTTPS
        
        # ç›¸åŒåç§°ä¿ç•™HTTPS
        if name not in filtered or (proto == "https" and filtered[name]["URL"].split(":")[0].lower() != "https"):
            filtered[name] = tunnel
    
    return sorted(filtered.values(), key=lambda x: x["éš§é“åç§°"])


def print_tunnel_table(columns, tunnel_data, title):
    """é€šç”¨è¡¨æ ¼æ‰“å°å‡½æ•°"""
    if not tunnel_data:
        print(f"æ²¡æœ‰{title}éš§é“ä¿¡æ¯")
        return
    
    # è®¡ç®—åˆ—å®½
    column_widths = defaultdict(int)
    for col in columns:
        column_widths[col] = len(col)
    for tunnel in tunnel_data:
        for col in columns:
            value = str(tunnel[col])
            if col == "URL" and len(value) > 50:
                value = value[:47] + "..."
            column_widths[col] = max(column_widths[col], len(value))
    
    # æ‰“å°è¡¨æ ¼
    header = " | ".join([f"{col.ljust(column_widths[col])}" for col in columns])
    print("\n" + "="*len(header))
    print(f"=== {title}ï¼ˆå…± {len(tunnel_data)} æ¡ï¼‰ ===")
    print(header)
    print("-"*len(header))
    for idx, tunnel in enumerate(tunnel_data, 1):
        row = []
        for col in columns:
            value = str(tunnel[col])
            if col == "URL" and len(value) > 50:
                value = value[:47] + "..."
            row.append(value.ljust(column_widths[col]))
        print(f"{idx}. " + " | ".join(row))
    print("="*len(header) + "\n")


def auto_open_url():
    """è¶…æ—¶è‡ªåŠ¨æ‰“å¼€é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„éš§é“URL"""
    global g_selected_url
    if g_selected_url:
        print(f"\nâŒ›5ç§’æœªè¾“å…¥ï¼Œè‡ªåŠ¨æ‰“å¼€é…ç½®ä¸­æŒ‡å®šçš„éš§é“...")
        webbrowser.open(g_selected_url)
    else:
        print(f"\nâŒ›5ç§’æœªè¾“å…¥ï¼Œä½†æœªæ‰¾åˆ°é…ç½®ä¸­æŒ‡å®šçš„éš§é“")


def user_select_tunnel(filtered_tunnels, auto_tunnel_name):
    """ç”¨æˆ·é€‰æ‹©éš§é“ï¼Œæ”¯æŒè¶…æ—¶è‡ªåŠ¨æ‰“å¼€ï¼ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„éš§é“åç§°ï¼‰"""
    global g_selected_url, g_timer

    # æŸ¥æ‰¾é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„éš§é“URLï¼ˆç”¨äºè¶…æ—¶è‡ªåŠ¨æ‰“å¼€ï¼‰
    for tunnel in filtered_tunnels:
        if tunnel["éš§é“åç§°"] == auto_tunnel_name:
            g_selected_url = tunnel["URL"]
            break

    # å¯åŠ¨3ç§’å®šæ—¶å™¨
    g_timer = Timer(5, auto_open_url)
    g_timer.start()

    try:
        choice = input(f"è¯·è¾“å…¥è¦æ‰“å¼€çš„éš§é“åºå·ï¼ˆ1-{len(filtered_tunnels)}ï¼Œ3ç§’æœªè¾“å…¥è‡ªåŠ¨æ‰“å¼€[{auto_tunnel_name}]ï¼Œè¾“å…¥qé€€å‡ºï¼‰: ")
        g_timer.cancel()  # å–æ¶ˆå®šæ—¶å™¨

        if choice.lower() == "q":
            print("ç¨‹åºå·²é€€å‡º")
            return
        index = int(choice) - 1
        if 0 <= index < len(filtered_tunnels):
            selected_url = filtered_tunnels[index]["URL"]
            print(f"ğŸ” æ­£åœ¨æ‰“å¼€: {selected_url}")
            webbrowser.open(selected_url)
        else:
            print("âŒ åºå·æ— æ•ˆ")
    except ValueError:
        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
    except Exception as e:
        print(f"é€‰æ‹©å‡ºé”™: {e}")


if __name__ == "__main__":
    try:
        # åŠ è½½é…ç½®ï¼ˆåŒ…å«è‡ªåŠ¨æ‰“å¼€çš„éš§é“åç§°ï¼‰
        config = load_config()
        auto_tunnel_name = config["AUTO_OPEN_TUNNEL"]  # ä»é…ç½®ä¸­è·å–è‡ªåŠ¨æ‰“å¼€çš„éš§é“åç§°
        
        # è·å–éš§é“ä¿¡æ¯
        print("å¼€å§‹è·å–cpolaréš§é“ä¿¡æ¯\n")
        html_content = login(config)
        if not html_content:
            exit()
        
        # è§£æå¹¶æ‰“å°å®Œæ•´åˆ—è¡¨
        columns, all_tunnels = parse_cpolar_tunnels(html_content)
        print_tunnel_table(columns, all_tunnels, "å®Œæ•´éš§é“åˆ—è¡¨")
        
        # è¿‡æ»¤å¹¶æ‰“å°HTTP/HTTPSåˆ—è¡¨
        filtered_tunnels = filter_http_https_tunnels(all_tunnels)
        print_tunnel_table(columns, filtered_tunnels, "è¿‡æ»¤åçš„HTTP/HTTPSéš§é“åˆ—è¡¨")
        
        # ç”¨æˆ·é€‰æ‹©ï¼ˆæ”¯æŒè¶…æ—¶è‡ªåŠ¨æ‰“å¼€é…ç½®ä¸­çš„éš§é“ï¼‰
        if filtered_tunnels:
            user_select_tunnel(filtered_tunnels, auto_tunnel_name)

    except Exception as e:
        print(f"æ“ä½œå¤±è´¥ï¼š{str(e)}")
        input("\næŒ‰å›è½¦é”®é€€å‡º...") 